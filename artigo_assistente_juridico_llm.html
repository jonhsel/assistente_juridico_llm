<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Fine-Tuning de LLM para Assistente Jur√≠dico ‚Äî Jonh Selmo</title>
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,700;0,900;1,400;1,700&family=Source+Serif+4:ital,opsz,wght@0,8..60,300;0,8..60,400;0,8..60,600;1,8..60,300;1,8..60,400&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet" />
  <style>
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    :root {
      --ink:       #1a1410;
      --ink-light: #4a3f35;
      --cream:     #f8f4ef;
      --warm-mid:  #ede6db;
      --accent:    #8b1a1a;
      --accent-2:  #c4832a;
      --rule:      #c8b8a2;
      --code-bg:   #2a2118;
      --code-text: #e8d5b0;
    }

    html { scroll-behavior: smooth; }

    body {
      background: var(--cream);
      color: var(--ink);
      font-family: 'Source Serif 4', Georgia, serif;
      font-size: 18px;
      line-height: 1.8;
      font-weight: 300;
    }

    /* ‚îÄ‚îÄ HEADER ‚îÄ‚îÄ */
    header {
      background: var(--ink);
      color: var(--cream);
      padding: 0;
      position: relative;
      overflow: hidden;
    }

    .header-noise {
      position: absolute; inset: 0;
      background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 200 200' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='n'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.85' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23n)' opacity='0.04'/%3E%3C/svg%3E");
      opacity: 0.6;
    }

    .header-inner {
      position: relative;
      max-width: 820px;
      margin: 0 auto;
      padding: 72px 40px 60px;
    }

    .header-label {
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.18em;
      text-transform: uppercase;
      color: var(--accent-2);
      margin-bottom: 28px;
      display: flex;
      align-items: center;
      gap: 14px;
    }

    .header-label::after {
      content: '';
      flex: 1;
      height: 1px;
      background: var(--accent-2);
      opacity: 0.4;
      max-width: 80px;
    }

    h1 {
      font-family: 'Playfair Display', serif;
      font-size: clamp(2.1rem, 5vw, 3.4rem);
      font-weight: 900;
      line-height: 1.15;
      letter-spacing: -0.01em;
      color: var(--cream);
      margin-bottom: 32px;
    }

    h1 em {
      font-style: italic;
      color: var(--accent-2);
    }

    .byline {
      display: flex;
      align-items: center;
      gap: 16px;
      border-top: 1px solid rgba(255,255,255,0.12);
      padding-top: 24px;
    }

    .byline-avatar {
      width: 42px; height: 42px;
      border-radius: 50%;
      background: var(--accent);
      display: flex; align-items: center; justify-content: center;
      font-family: 'Playfair Display', serif;
      font-size: 18px;
      font-weight: 700;
      color: var(--cream);
      flex-shrink: 0;
    }

    .byline-text {
      font-size: 14px;
      color: rgba(248, 244, 239, 0.75);
      font-style: italic;
    }

    .byline-text strong {
      display: block;
      color: var(--cream);
      font-style: normal;
      font-weight: 600;
      font-size: 15px;
    }

    /* ‚îÄ‚îÄ PROGRESS BAR ‚îÄ‚îÄ */
    #progress {
      position: fixed; top: 0; left: 0;
      height: 3px;
      background: linear-gradient(90deg, var(--accent), var(--accent-2));
      width: 0%;
      z-index: 999;
      transition: width 0.1s linear;
    }

    /* ‚îÄ‚îÄ TOC ‚îÄ‚îÄ */
    nav.toc {
      background: var(--warm-mid);
      border-left: 3px solid var(--accent);
      max-width: 820px;
      margin: 0 auto;
      padding: 28px 40px;
    }

    nav.toc h2 {
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.16em;
      text-transform: uppercase;
      color: var(--accent);
      margin-bottom: 16px;
    }

    nav.toc ol {
      list-style: none;
      counter-reset: toc;
    }

    nav.toc li {
      counter-increment: toc;
      display: flex;
      gap: 12px;
      align-items: baseline;
      padding: 4px 0;
      border-bottom: 1px dotted var(--rule);
    }

    nav.toc li:last-child { border-bottom: none; }

    nav.toc li::before {
      content: counter(toc, decimal-leading-zero);
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      color: var(--accent-2);
      flex-shrink: 0;
    }

    nav.toc a {
      color: var(--ink-light);
      text-decoration: none;
      font-size: 15px;
      font-weight: 300;
      transition: color 0.2s;
    }

    nav.toc a:hover { color: var(--accent); }

    /* ‚îÄ‚îÄ ARTICLE BODY ‚îÄ‚îÄ */
    .article-body {
      max-width: 820px;
      margin: 0 auto;
      padding: 64px 40px 80px;
    }

    .lead {
      font-size: 1.2em;
      font-weight: 300;
      line-height: 1.7;
      color: var(--ink-light);
      border-bottom: 1px solid var(--rule);
      padding-bottom: 40px;
      margin-bottom: 56px;
    }

    .lead strong { color: var(--ink); font-weight: 600; }

    /* ‚îÄ‚îÄ SECTION HEADINGS ‚îÄ‚îÄ */
    h2 {
      font-family: 'Playfair Display', serif;
      font-size: clamp(1.5rem, 3vw, 2rem);
      font-weight: 700;
      line-height: 1.25;
      color: var(--ink);
      margin: 64px 0 24px;
      padding-top: 48px;
      border-top: 2px solid var(--ink);
      position: relative;
    }

    h2::before {
      content: attr(data-num);
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.12em;
      color: var(--accent-2);
      display: block;
      margin-bottom: 8px;
    }

    h3 {
      font-family: 'Playfair Display', serif;
      font-size: 1.25rem;
      font-style: italic;
      font-weight: 400;
      color: var(--accent);
      margin: 40px 0 16px;
    }

    p { margin-bottom: 1.5em; }
    p:last-child { margin-bottom: 0; }

    strong { font-weight: 600; color: var(--ink); }
    em { font-style: italic; }

    /* ‚îÄ‚îÄ COMPARISON CARDS ‚îÄ‚îÄ */
    .approach-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 20px;
      margin: 36px 0 48px;
    }

    .approach-card {
      background: white;
      border: 1px solid var(--rule);
      border-top: 4px solid var(--rule);
      padding: 24px 20px;
      position: relative;
      transition: transform 0.2s, box-shadow 0.2s;
    }

    .approach-card:hover {
      transform: translateY(-3px);
      box-shadow: 0 8px 24px rgba(26,20,16,0.1);
    }

    .approach-card.rag  { border-top-color: #4a7c99; }
    .approach-card.api  { border-top-color: var(--accent-2); }
    .approach-card.fine { border-top-color: var(--accent); }

    .card-tag {
      font-family: 'JetBrains Mono', monospace;
      font-size: 10px;
      letter-spacing: 0.14em;
      text-transform: uppercase;
      margin-bottom: 12px;
      display: block;
    }

    .approach-card.rag  .card-tag { color: #4a7c99; }
    .approach-card.api  .card-tag { color: var(--accent-2); }
    .approach-card.fine .card-tag { color: var(--accent); }

    .card-title {
      font-family: 'Playfair Display', serif;
      font-size: 1.05rem;
      font-weight: 700;
      margin-bottom: 12px;
      color: var(--ink);
    }

    .card-pro, .card-con {
      font-size: 13.5px;
      line-height: 1.6;
      display: flex;
      gap: 8px;
      margin-bottom: 6px;
    }

    .card-pro::before { content: '‚úì'; color: #3a7a3a; flex-shrink: 0; font-weight: 700; }
    .card-con::before { content: '‚úó'; color: var(--accent); flex-shrink: 0; font-weight: 700; }

    .card-divider {
      border: none;
      border-top: 1px dashed var(--rule);
      margin: 14px 0;
    }

    /* ‚îÄ‚îÄ PROS/CONS INLINE ‚îÄ‚îÄ */
    .pros-cons {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 20px;
      margin: 24px 0;
    }

    @media (max-width: 600px) {
      .pros-cons { grid-template-columns: 1fr; }
      .approach-grid { grid-template-columns: 1fr; }
    }

    .pros-box, .cons-box {
      padding: 20px;
      border-radius: 2px;
    }

    .pros-box { background: #f0f7f0; border-left: 3px solid #3a7a3a; }
    .cons-box { background: #fdf0f0; border-left: 3px solid var(--accent); }

    .pros-box h4, .cons-box h4 {
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.14em;
      text-transform: uppercase;
      margin-bottom: 12px;
    }

    .pros-box h4 { color: #3a7a3a; }
    .cons-box h4 { color: var(--accent); }

    .pros-box ul, .cons-box ul {
      list-style: none;
      font-size: 14.5px;
      line-height: 1.65;
    }

    .pros-box li, .cons-box li { margin-bottom: 6px; }

    /* ‚îÄ‚îÄ PARAMS TABLE ‚îÄ‚îÄ */
    .params-table {
      width: 100%;
      border-collapse: collapse;
      margin: 28px 0;
      font-size: 15px;
    }

    .params-table th {
      background: var(--ink);
      color: var(--cream);
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.12em;
      text-transform: uppercase;
      padding: 12px 16px;
      text-align: left;
      font-weight: 500;
    }

    .params-table td {
      padding: 11px 16px;
      border-bottom: 1px solid var(--rule);
      vertical-align: top;
    }

    .params-table tr:nth-child(even) td { background: var(--warm-mid); }

    .params-table td:first-child {
      font-family: 'JetBrains Mono', monospace;
      font-size: 13px;
      color: var(--accent-2);
      white-space: nowrap;
    }

    /* ‚îÄ‚îÄ ROUGE CARDS ‚îÄ‚îÄ */
    .rouge-grid {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 16px;
      margin: 28px 0;
    }

    @media (max-width: 580px) { .rouge-grid { grid-template-columns: 1fr; } }

    .rouge-card {
      background: var(--ink);
      color: var(--cream);
      padding: 28px 20px;
      position: relative;
      overflow: hidden;
    }

    .rouge-card::before {
      content: '';
      position: absolute;
      top: -20px; right: -20px;
      width: 80px; height: 80px;
      border-radius: 50%;
      opacity: 0.07;
      background: var(--cream);
    }

    .rouge-name {
      font-family: 'Playfair Display', serif;
      font-size: 2rem;
      font-weight: 900;
      color: var(--accent-2);
      line-height: 1;
      margin-bottom: 10px;
    }

    .rouge-sub {
      font-family: 'JetBrains Mono', monospace;
      font-size: 10px;
      letter-spacing: 0.14em;
      text-transform: uppercase;
      color: rgba(248,244,239,0.5);
      margin-bottom: 14px;
    }

    .rouge-desc {
      font-size: 13.5px;
      line-height: 1.65;
      color: rgba(248,244,239,0.8);
      font-weight: 300;
    }

    /* ‚îÄ‚îÄ BLOCKQUOTE ‚îÄ‚îÄ */
    blockquote {
      margin: 32px 0;
      padding: 24px 28px;
      background: var(--warm-mid);
      border-left: 4px solid var(--accent-2);
      font-style: italic;
      color: var(--ink-light);
      position: relative;
    }

    blockquote::before {
      content: '\201C';
      font-family: 'Playfair Display', serif;
      font-size: 5rem;
      color: var(--accent-2);
      opacity: 0.2;
      position: absolute;
      top: -10px; left: 10px;
      line-height: 1;
    }

    blockquote p { margin: 0; font-size: 1.05em; position: relative; }

    blockquote + blockquote {
      border-left-color: var(--accent);
      background: white;
    }

    /* ‚îÄ‚îÄ CODE ‚îÄ‚îÄ */
    code {
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.82em;
      background: var(--code-bg);
      color: var(--code-text);
      padding: 2px 7px;
      border-radius: 3px;
    }

    /* ‚îÄ‚îÄ CALLOUT ‚îÄ‚îÄ */
    .callout {
      background: linear-gradient(135deg, var(--ink) 0%, #2f1f0f 100%);
      color: var(--cream);
      padding: 36px 40px;
      margin: 48px 0;
      position: relative;
      overflow: hidden;
    }

    .callout::after {
      content: '‚öñ';
      position: absolute;
      right: 30px; bottom: -10px;
      font-size: 8rem;
      opacity: 0.05;
      line-height: 1;
    }

    .callout-label {
      font-family: 'JetBrains Mono', monospace;
      font-size: 10px;
      letter-spacing: 0.18em;
      text-transform: uppercase;
      color: var(--accent-2);
      margin-bottom: 12px;
    }

    .callout p {
      font-size: 1.05em;
      line-height: 1.75;
      color: rgba(248,244,239,0.88);
      margin: 0;
    }

    .callout strong { color: var(--accent-2); }

    /* ‚îÄ‚îÄ CONCLUSION BOX ‚îÄ‚îÄ */
    .conclusion {
      border: 2px solid var(--ink);
      padding: 40px;
      margin-top: 64px;
      position: relative;
    }

    .conclusion-label {
      position: absolute;
      top: -13px; left: 24px;
      background: var(--cream);
      padding: 0 12px;
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.14em;
      text-transform: uppercase;
      color: var(--accent);
    }

    /* ‚îÄ‚îÄ FOOTER ‚îÄ‚îÄ */
    footer {
      background: var(--ink);
      color: rgba(248,244,239,0.55);
      text-align: center;
      padding: 40px;
      font-size: 14px;
      font-style: italic;
    }

    footer strong {
      color: var(--cream);
      font-style: normal;
    }

    /* ‚îÄ‚îÄ ANIMATIONS ‚îÄ‚îÄ */
    .fade-in {
      opacity: 0;
      transform: translateY(18px);
      transition: opacity 0.6s ease, transform 0.6s ease;
    }

    .fade-in.visible {
      opacity: 1;
      transform: translateY(0);
    }

    /* ‚îÄ‚îÄ RULE ‚îÄ‚îÄ */
    hr {
      border: none;
      border-top: 1px solid var(--rule);
      margin: 48px 0;
    }

    /* ‚îÄ‚îÄ DECISION BANNER ‚îÄ‚îÄ */
    .decision-banner {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 0;
      margin: 32px 0;
      border: 1px solid var(--rule);
      overflow: hidden;
    }

    @media (max-width: 600px) { .decision-banner { grid-template-columns: 1fr; } }

    .decision-item {
      padding: 22px 18px;
      border-right: 1px solid var(--rule);
      font-size: 14px;
      line-height: 1.6;
    }

    .decision-item:last-child { border-right: none; }

    .decision-item strong {
      display: block;
      font-family: 'JetBrains Mono', monospace;
      font-size: 10px;
      letter-spacing: 0.14em;
      text-transform: uppercase;
      margin-bottom: 8px;
    }

    .decision-item:nth-child(1) strong { color: #4a7c99; }
    .decision-item:nth-child(2) strong { color: var(--accent-2); }
    .decision-item:nth-child(3) strong { color: var(--accent); }

    .decision-item:nth-child(1) { background: #f5f9fc; }
    .decision-item:nth-child(2) { background: #fdf8f2; }
    .decision-item:nth-child(3) { background: #fdf5f5; }
  </style>
</head>
<body>

<div id="progress"></div>

<!-- ‚îÄ‚îÄ HEADER ‚îÄ‚îÄ -->
<header>
  <div class="header-noise"></div>
  <div class="header-inner">
    <div class="header-label">Engenharia de IA &nbsp;¬∑&nbsp; NLP &nbsp;¬∑&nbsp; LLMs</div>
    <h1>Fine-Tuning de LLM <em>Open-Source</em> para um Assistente Jur√≠dico</h1>
    <p style="color:rgba(248,244,239,0.6);font-size:1rem;margin-bottom:28px;">Uma Prova de Conceito com FLAN-T5 e M√©tricas ROUGE</p>
    <div class="byline">
      <div class="byline-avatar">JS</div>
      <div class="byline-text">
        <strong>Jonh Selmo</strong>
        Engenheiro de IA ¬∑ Processamento de Linguagem Natural &amp; IA Generativa
      </div>
    </div>
    <figure style="margin-top:24px;">
      <img src="images/1.png" alt="Ilustra√ß√£o: Assistente Jur√≠dico - diagrama" style="width:100%;max-width:720px;height:auto;border-radius:8px;display:block;margin:0 auto;box-shadow:0 8px 24px rgba(26,20,16,0.12);">
    </figure>
  </div>
</header>

<!-- ‚îÄ‚îÄ TABLE OF CONTENTS ‚îÄ‚îÄ -->
<nav class="toc" aria-label="√çndice">
  <h2>√çndice</h2>
  <ol>
    <li><a href="#abordagens">Tr√™s Abordagens, Tr√™s Filosofias</a></li>
    <li><a href="#arquitetura">A Arquitetura: por que o FLAN-T5?</a></li>
    <li><a href="#dataset">O Dataset: Limitado por Design</a></li>
    <li><a href="#finetuning">O Processo de Fine-Tuning</a></li>
    <li><a href="#rouge">M√©tricas ROUGE</a></li>
    <li><a href="#generalizacao">Capacidade de Generaliza√ß√£o</a></li>
    <li><a href="#deploy">Deploy e Infer√™ncia</a></li>
    <li><a href="#conclusao">Conclus√µes e Pr√≥ximos Passos</a></li>
  </ol>
</nav>

<!-- ‚îÄ‚îÄ ARTICLE BODY ‚îÄ‚îÄ -->
<article class="article-body">

  <!-- INTRO -->
  <p class="lead fade-in">
    A intelig√™ncia artificial generativa tem transformado a forma como interagimos com sistemas de informa√ß√£o. Uma das aplica√ß√µes mais promissoras ‚Äî e ao mesmo tempo mais desafiadoras ‚Äî √© a cria√ß√£o de assistentes especializados em dom√≠nios t√©cnicos, como o Direito. Neste artigo, apresento um projeto que desenvolvi aplicando a t√©cnica de <strong>fine-tuning</strong> em um modelo de linguagem de grande escala (LLM) open-source para construir um prot√≥tipo de assistente jur√≠dico capaz de responder perguntas sobre procedimentos e obriga√ß√µes legais.
  </p>

  <!-- SE√á√ÉO 1 -->
  <h2 id="abordagens" data-num="01 ‚Äî Comparativo" class="fade-in">Tr√™s Abordagens, Tr√™s Filosofias: Fine-Tuning, Assistentes Online e LLMs por API</h2>

  <figure style="margin-top:24px;">
      <img src="images/2.png" alt="Ilustra√ß√£o: abordagens de assistente jur√≠dico" style="width:100%;max-width:720px;height:auto;border-radius:8px;display:block;margin:0 auto;box-shadow:0 8px 24px rgba(26,20,16,0.12);">
  </figure>

  <p class="fade-in">Antes de entrar nos detalhes t√©cnicos do projeto, vale responder uma pergunta que qualquer profissional ou gestor faria ao se deparar com essa solu√ß√£o: <em>"por que construir um modelo pr√≥prio se ferramentas como o NotebookLM do Google ou APIs de LLMs como GPT-4 e Claude j√° existem e funcionam bem?"</em> A resposta depende de prioridades que variam conforme o contexto ‚Äî privacidade, custo, controle e escalabilidade t√™m pesos diferentes para cada organiza√ß√£o.</p>

  <div class="approach-grid fade-in">

    <div class="approach-card rag">
      <span class="card-tag">Assistentes Online</span>
      <div class="card-title">NotebookLM &amp; similares (RAG)</div>
      <hr class="card-divider">
      <div class="card-pro">Setup imediato, sem c√≥digo</div>
      <div class="card-pro">Alta qualidade em documentos estruturados</div>
      <div class="card-pro">Ideal para uso individual</div>
      <hr class="card-divider">
      <div class="card-con">Dados trafegam em servidores de terceiros</div>
      <div class="card-con">Sem customiza√ß√£o profunda</div>
      <div class="card-con">Barreira para sigilo e LGPD</div>
    </div>

    <div class="approach-card api">
      <span class="card-tag">API Comercial</span>
      <div class="card-title">GPT-4, Claude, Gemini‚Ä¶</div>
      <hr class="card-divider">
      <div class="card-pro">Racioc√≠nio de estado da arte</div>
      <div class="card-pro">Integra√ß√£o simples, sem GPU pr√≥pria</div>
      <div class="card-pro">Atualiza√ß√µes autom√°ticas do modelo</div>
      <hr class="card-divider">
      <div class="card-con">Dados passam pela infra do provedor</div>
      <div class="card-con">Custo por token em alto volume</div>
      <div class="card-con">Vendor lock-in</div>
    </div>

    <div class="approach-card fine">
      <span class="card-tag">Fine-Tuning Open-Source</span>
      <div class="card-title">FLAN-T5, Mistral, LLaMA‚Ä¶</div>
      <hr class="card-divider">
      <div class="card-pro">Dados 100% sob controle interno</div>
      <div class="card-pro">Custo marginal zero ap√≥s treino</div>
      <div class="card-pro">Pode rodar offline / air-gapped</div>
      <hr class="card-divider">
      <div class="card-con">Exige expertise t√©cnica em ML</div>
      <div class="card-con">Racioc√≠nio inferior a modelos gigantes</div>
      <div class="card-con">Manuten√ß√£o √© responsabilidade interna</div>
    </div>

  </div>



  <h3>Assistentes Online com RAG (NotebookLM e similares)</h3>
  <p class="fade-in">Ferramentas como o <strong>NotebookLM</strong> operam sob o paradigma de <strong>RAG</strong> (<em>Retrieval-Augmented Generation</em>): o usu√°rio fornece documentos e o sistema os indexa como base de conhecimento, respondendo perguntas com refer√™ncia direta a esses textos. √â uma abordagem poderosa e democraticamente acess√≠vel, com curva de ado√ß√£o quase nula.</p>

  <p class="fade-in">Os pontos fortes s√£o evidentes: nenhum conhecimento t√©cnico √© necess√°rio, o setup √© imediato, e a qualidade das respostas para documentos bem estruturados costuma ser alta. Para equipes jur√≠dicas que precisam consultar contratos, pareceres ou legisla√ß√µes espec√≠ficas rapidamente, o NotebookLM entrega valor real em minutos. O ponto fraco cr√≠tico em contextos corporativos sens√≠veis √© que toda informa√ß√£o enviada trafega e √© processada em servidores de terceiros ‚Äî o que, para escrit√≥rios de advocacia ou qualquer ambiente que lide com sigilo coberto pela LGPD, √© uma barreira frequentemente intranspon√≠vel.</p>

  <h3>LLMs por API (GPT-4, Claude, Gemini e similares)</h3>
  <p class="fade-in">O acesso a grandes modelos de linguagem via <strong>API</strong> oferece um equil√≠brio diferente. Com poucas linhas de c√≥digo, √© poss√≠vel integrar a capacidade de racioc√≠nio de modelos de √∫ltima gera√ß√£o a qualquer aplica√ß√£o, usando t√©cnicas como <em>prompt engineering</em> avan√ßado, <em>few-shot prompting</em> ou RAG implementado pelo pr√≥prio desenvolvedor sobre infraestrutura controlada.</p>

  <p class="fade-in">Os pontos fracos gravitam em torno de tr√™s eixos. Primeiro, <strong>privacidade e soberania dos dados</strong>: mesmo com acordos de processamento de dados (DPA), os dados de entrada ainda trafegam pela infraestrutura do provedor. Segundo, <strong>custo operacional</strong>: em aplica√ß√µes de alto volume, o custo por token acumula-se rapidamente. Terceiro, <strong>depend√™ncia de fornecedor</strong> (<em>vendor lock-in</em>): mudan√ßas de pre√ßo, descontinua√ß√£o de modelos ou altera√ß√µes nos termos de uso est√£o completamente fora do controle da organiza√ß√£o.</p>

  <h3>Fine-Tuning de LLM Open-Source: Controle Total, Custo de Entrada Maior</h3>
  <p class="fade-in">A abordagem adotada neste projeto ocupa o outro extremo do espectro. Ela exige mais: conhecimento t√©cnico em ML, infraestrutura computacional e curadoria de dados. Em contrapartida, oferece algo que as alternativas n√£o conseguem garantir plenamente: <strong>controle absoluto</strong>. Os dados nunca saem do ambiente controlado pela organiza√ß√£o, eliminando riscos de vazamento e garantindo conformidade com a LGPD e com obriga√ß√µes de sigilo profissional da OAB. Ap√≥s o investimento inicial em treinamento, o custo marginal de infer√™ncia √© praticamente zero.</p>

  <h3>Qual abordagem escolher?</h3>

  <div class="decision-banner fade-in">
    <div class="decision-item">
      <strong>üîµ Explora√ß√£o r√°pida</strong>
      Assistentes online como o NotebookLM s√£o imbat√≠veis em praticidade para uso individual sem restri√ß√µes de privacidade.
    </div>
    <div class="decision-item">
      <strong>üü° Corporativo de m√©dio porte</strong>
      APIs de LLMs oferecem o melhor custo-benef√≠cio de qualidade versus esfor√ßo sem restri√ß√µes severas de privacidade.
    </div>
    <div class="decision-item">
      <strong>üî¥ Dados sens√≠veis / alto volume</strong>
      O fine-tuning open-source √© o caminho mais robusto e sustent√°vel para ambientes com sigilo absoluto e necessidade de customiza√ß√£o profunda.
    </div>
  </div>

  <p class="fade-in">Este projeto demonstra que essa terceira via √© mais acess√≠vel do que parece ‚Äî e que at√© mesmo com um dataset de 25 exemplos √© poss√≠vel obter resultados funcionais, abrindo caminho para evolu√ß√µes incrementais dentro de uma infraestrutura completamente sob controle da organiza√ß√£o.</p>

  <!-- SE√á√ÉO 2 -->
  <h2 id="arquitetura" data-num="02 ‚Äî Arquitetura" class="fade-in">A Arquitetura: por que o FLAN-T5?</h2>

  <p class="fade-in">O modelo escolhido para este projeto foi o <strong>FLAN-T5-Base</strong>, dispon√≠vel no Hugging Face atrav√©s do identificador <code>google/flan-t5-base</code>. Trata-se de uma vers√£o refinada do T5 (<em>Text-to-Text Transfer Transformer</em>), treinada com a estrat√©gia FLAN (<em>Fine-tuned Language Net</em>), que exp√µe o modelo a centenas de tarefas distintas durante o pr√©-treinamento ‚Äî incluindo racioc√≠nio, sumariza√ß√£o e resposta a perguntas.</p>

  <p class="fade-in">Modelos da fam√≠lia T5 tratam toda tarefa de NLP como um problema de gera√ß√£o de texto, onde tanto a entrada quanto a sa√≠da s√£o sequ√™ncias textuais. Isso torna a arquitetura naturalmente adapt√°vel a cen√°rios de pergunta-resposta (QA), que √© exatamente o formato do assistente jur√≠dico proposto. A implementa√ß√£o utilizou o ecossistema da biblioteca <strong>Transformers da Hugging Face</strong>, combinando o <code>T5Tokenizer</code>, <code>T5ForConditionalGeneration</code> e o <code>Seq2SeqTrainer</code> ‚Äî uma stack robusta e amplamente adotada pela comunidade de NLP.</p>

  <!-- SE√á√ÉO 3 -->
  <h2 id="dataset" data-num="03 ‚Äî Dataset" class="fade-in">O Dataset: Limitado por Design, Poderoso pelo Modelo Base</h2>

  <p class="fade-in">Uma das caracter√≠sticas mais marcantes deste projeto √© a escala intencional do conjunto de dados: apenas <strong>25 exemplos no total</strong>, divididos em 20 para treino e 5 para teste, em formato CSV com duas colunas ‚Äî <code>question</code> e <code>answer</code>. As perguntas abordam temas processuais brasileiros, como obriga√ß√µes de comunica√ß√£o ao Ju√≠zo, prazos e arquivamentos.</p>

  <div class="callout fade-in">
    <div class="callout-label">Conceito-chave</div>
    <p>O <strong>fine-tuning n√£o cria conhecimento do zero</strong>. Ele <em>direciona</em> o conhecimento j√° cristalizado no modelo pr√©-treinado para um dom√≠nio espec√≠fico, ajustando pesos que j√° representam padr√µes sofisticados de linguagem aprendidos em bilh√µes de tokens. Com apenas 20 exemplos, n√£o estamos ensinando portugu√™s jur√≠dico ao modelo ‚Äî estamos mostrando o caminho para um conhecimento que ele j√° possui.</p>
  </div>

  <p class="fade-in">O pr√©-processamento aplicou o prefixo <code>"answer the question:"</code> a cada pergunta antes da tokeniza√ß√£o, com comprimento m√°ximo de 128 tokens para as entradas e 512 tokens para as respostas. Esse prefixo serve como instru√ß√£o expl√≠cita para o modelo, uma t√©cnica conhecida como <em>prompt engineering no n√≠vel do treinamento</em>.</p>

  <figure style="margin-top:24px;">
      <img src="images/3.png" alt="Ilustra√ß√£o: capacidade de generaliza√ß√£o do assistente jur√≠dico" style="width:100%;max-width:720px;height:auto;border-radius:8px;display:block;margin:0 auto;box-shadow:0 8px 24px rgba(26,20,16,0.12);">
  </figure>

  <!-- SE√á√ÉO 4 -->
  <h2 id="finetuning" data-num="04 ‚Äî Treinamento" class="fade-in">O Processo de Fine-Tuning</h2>

  <p class="fade-in">O treinamento foi conduzido com os seguintes hiperpar√¢metros:</p>

  <table class="params-table fade-in">
    <thead>
      <tr>
        <th>Par√¢metro</th>
        <th>Valor</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>√âpocas</td><td>6</td></tr>
      <tr><td>Taxa de aprendizado</td><td>3e-4 (0,0003)</td></tr>
      <tr><td>Batch size (treino)</td><td>4 exemplos por dispositivo</td></tr>
      <tr><td>Batch size (avalia√ß√£o)</td><td>2 exemplos por dispositivo</td></tr>
      <tr><td>Weight decay</td><td>0,01</td></tr>
      <tr><td>Estrat√©gia de avalia√ß√£o</td><td>Ao final de cada √©poca</td></tr>
      <tr><td>Passos globais</td><td>30</td></tr>
      <tr><td>Perda final de treino</td><td>‚âà 1,76</td></tr>
      <tr><td>Tempo total</td><td>‚âà 71 segundos</td></tr>
    </tbody>
  </table>

  <p class="fade-in">O modelo treinado foi salvo localmente na pasta <code>modelo_salvo/</code>, utilizando os m√©todos padr√£o do <code>Seq2SeqTrainer</code>, garantindo portabilidade e reutiliza√ß√£o sem necessidade de re-treinamento.</p>

  <figure class="fade-in" style="margin-top:18px;">
    <figcaption style="font-family: 'JetBrains Mono', monospace;font-size:12px;color:var(--ink-light);margin-bottom:8px;">Exemplo: sa√≠da do treinamento (logs)</figcaption>
    <pre style="background:#f6f2e9;border:1px solid var(--rule);padding:16px;border-radius:6px;overflow:auto;font-family: 'JetBrains Mono', monospace;font-size:13px;line-height:1.4;">
[30/30 01:10, Epoch 6/6]

Epoch    Training Loss    Validation Loss    Rouge1    Rouge2    Rougel    Rougelsum

1    2.196200    2.637834    0.171980    0.049114    0.168126    0.165428
2    2.083000    2.449079    0.131731    0.020455    0.124761    0.123586
3    1.647700    2.347261    0.126269    0.048884    0.115766    0.116027
4    1.393500    2.303102    0.140474    0.048394    0.113775    0.115361
5    1.869200    2.284526    0.140474    0.036629    0.113775    0.115361
6    1.278400    2.278221    0.140474    0.036629    0.113775    0.115361

CPU times: user 19.7 s, sys: 3.57 s, total: 23.3 s
Wall time: 1min 11s
TrainOutput(global_step=30, training_loss=1.758737603823344, metrics={'train_runtime': 71.2563, 'train_samples_per_second': 1.684, 'train_steps_per_second': 0.421, 'total_flos': 7409288540160.0, 'train_loss': 1.758737603823344, 'epoch': 6.0})
    </pre>
  </figure>

  <!-- SE√á√ÉO 5 -->
  <h2 id="rouge" data-num="05 ‚Äî Avalia√ß√£o" class="fade-in">M√©tricas ROUGE: Avaliando a Qualidade das Respostas Geradas</h2>

  <p class="fade-in">Para medir o desempenho do modelo, foi utilizado o conjunto de m√©tricas <strong>ROUGE</strong> (<em>Recall-Oriented Understudy for Gisting Evaluation</em>), carregado via a biblioteca <code>evaluate</code> do Hugging Face. ROUGE √© o padr√£o-ouro para avalia√ß√£o de sistemas de gera√ß√£o de texto, especialmente em tarefas de sumariza√ß√£o e resposta a perguntas.</p>

  <div class="rouge-grid fade-in">
    <div class="rouge-card">
      <div class="rouge-name">ROUGE-1</div>
      <div class="rouge-sub">Unigramas</div>
      <div class="rouge-desc">Mede a sobreposi√ß√£o de <strong style="color:var(--accent-2)">palavras individuais</strong> entre o texto gerado e a refer√™ncia. Responde: <em>"quantas palavras certas o modelo usou, em qualquer ordem?"</em> Um valor elevado indica que o modelo domina o vocabul√°rio do dom√≠nio jur√≠dico.</div>
    </div>
    <div class="rouge-card">
      <div class="rouge-name">ROUGE-2</div>
      <div class="rouge-sub">Bigramas</div>
      <div class="rouge-desc">Mede a sobreposi√ß√£o de <strong style="color:var(--accent-2)">pares consecutivos de palavras</strong>. Mais exigente: o modelo precisa n√£o s√≥ usar as palavras certas, mas combin√°-las na sequ√™ncia correta ‚Äî indicando dom√≠nio da estrutura frasal do dom√≠nio.</div>
    </div>
    <div class="rouge-card">
      <div class="rouge-name">ROUGE-L</div>
      <div class="rouge-sub">Subsequ√™ncia Comum</div>
      <div class="rouge-desc">Calcula a <strong style="color:var(--accent-2)">Longest Common Subsequence</strong> (LCS), levando em conta a ordem relativa das palavras, mas permitindo lacunas. Captura flu√™ncia e coer√™ncia global. Expresso como F1 entre precis√£o e recall sobre a LCS.</div>
    </div>
  </div>

  <p class="fade-in">Na implementa√ß√£o, as m√©tricas foram calculadas com <strong>stemming</strong> habilitado (<code>use_stemmer=True</code>), normalizando varia√ß√µes morfol√≥gicas ‚Äî essencial para o portugu√™s, idioma de alta flex√£o. O texto foi segmentado por senten√ßas via <code>nltk.sent_tokenize</code> antes do c√°lculo, garantindo que a avalia√ß√£o respeite os limites naturais de cada resposta.</p>

  <p class="fade-in">√â importante destacar que as m√©tricas ROUGE possuem limita√ß√µes: elas medem semelhan√ßa <em>lexical</em>, n√£o <em>sem√¢ntica</em>. Uma resposta juridicamente correta, por√©m formulada com sin√¥nimos diferentes da refer√™ncia, pode ter pontua√ß√£o ROUGE baixa. Em produ√ß√£o, recomenda-se complementar a avalia√ß√£o autom√°tica com an√°lise qualitativa por especialistas jur√≠dicos.</p>

  <!-- SE√á√ÉO 6 -->
  <h2 id="generalizacao" data-num="06 ‚Äî Generaliza√ß√£o" class="fade-in">Capacidade de Generaliza√ß√£o: o Paradoxo de Poucos Dados</h2>

  
  <p class="fade-in">O aspecto mais instigante deste projeto √© justamente a tens√£o entre a limita√ß√£o do dataset e a qualidade das respostas geradas. Ao submeter a pergunta:</p>

  <blockquote class="fade-in">
    <p>√â obrigat√≥ria a comunica√ß√£o do arquivamento ao Ju√≠zo competente?</p>
  </blockquote>

  <p class="fade-in">O modelo respondeu:</p>

  <blockquote class="fade-in">
    <p>A: Sim. O membro deve comunicar ao juzo competente ao atribui√ßo de arquivamento ao juzo competente.</p>
  </blockquote>

  <p class="fade-in">A resposta apresenta erros tipogr√°ficos ‚Äî consequ√™ncia da pequena base de dados e do curto treinamento ‚Äî mas √© <strong>semanticamente correta</strong>: confirma a obrigatoriedade, identifica o sujeito da a√ß√£o ("o membro") e o destinat√°rio ("o Ju√≠zo competente"). O modelo n√£o apenas memorizou ‚Äî ele generalizou.</p>

  <div class="pros-cons fade-in">
    <div class="pros-box">
      <h4>Transfer Learning profundo</h4>
      <ul>
        <li>FLAN-T5 foi pr√©-treinado em bilh√µes de tokens</li>
        <li>Aprendeu gram√°tica, racioc√≠nio condicional e padr√µes QA em m√∫ltiplos idiomas</li>
        <li>O fine-tuning apenas "sintonizou" esse conhecimento para o Direito brasileiro</li>
      </ul>
    </div>
    <div class="cons-box">
      <h4>Limites da generaliza√ß√£o</h4>
      <ul>
        <li>20 exemplos n√£o cobrem a amplitude do ordenamento jur√≠dico</li>
        <li>Erros tipogr√°ficos revelam fragilidade do dataset reduzido</li>
        <li>Risco de overfitting em dom√≠nios muito espec√≠ficos</li>
      </ul>
    </div>
  </div>

  <p class="fade-in">Modelos de linguagem modernos possuem uma capacidade not√°vel de extrapolar padr√µes a partir de poucos exemplos ‚Äî fen√¥meno √†s vezes chamado de <em>few-shot generalization</em>. Em cen√°rios reais, seria necess√°rio expandir substancialmente a base de dados, possivelmente incorporando textos de legisla√ß√£o, jurisprud√™ncia e doutrina.</p>

  <!-- SE√á√ÉO 7 -->
  <h2 id="deploy" data-num="07 ‚Äî Deploy" class="fade-in">Deploy e Infer√™ncia</h2>

  <p class="fade-in">Ap√≥s o treinamento, o modelo foi carregado via <code>AutoModelForSeq2SeqLM</code> e <code>AutoTokenizer</code> a partir do diret√≥rio salvo localmente ‚Äî um padr√£o que facilita o empacotamento e o eventual deploy em uma aplica√ß√£o web ou API REST. A infer√™ncia foi realizada com temperatura de <code>0.4</code> e amostragem ativada (<code>do_sample=True</code>), configura√ß√µes que balanceiam criatividade e determinismo nas respostas ‚Äî importante em contextos jur√≠dicos, onde a precis√£o √© priorit√°ria.</p>

  <!-- SE√á√ÉO 8 -->
  <h2 id="conclusao" data-num="08 ‚Äî Conclus√£o" class="fade-in">Conclus√µes e Pr√≥ximos Passos</h2>

  <div class="conclusion fade-in">
    <div class="conclusion-label">S√≠ntese</div>
    <p>Este projeto demonstra que √© poss√≠vel criar um prot√≥tipo funcional de assistente jur√≠dico utilizando um LLM open-source com recursos computacionais modestos e um dataset extremamente reduzido. A chave est√° em aproveitar o poder do transfer learning: o modelo traz consigo d√©cadas de texto humano processado, e o fine-tuning apenas o redireciona.</p>
    <br>
    <p>As m√©tricas ROUGE fornecem uma base quantitativa s√≥lida para acompanhar a evolu√ß√£o do modelo √† medida que o dataset cresce. O ROUGE-1 sinaliza dom√≠nio de vocabul√°rio, o ROUGE-2 indica estrutura frasal e o ROUGE-L avalia coer√™ncia global ‚Äî juntos, formam um painel de avalia√ß√£o abrangente para sistemas de gera√ß√£o de texto especializado.</p>
    <br>
    <p>Como evolu√ß√£o natural, os pr√≥ximos passos incluem a expans√£o do dataset com centenas ou milhares de pares QA jur√≠dicos, a experimenta√ß√£o com modelos maiores como o FLAN-T5-Large ou modelos nativos em portugu√™s como o <strong>BERTimbau</strong> e o <strong>Sabi√°-2</strong>, e a integra√ß√£o do modelo fine-tunado em uma interface web para uso pr√°tico por profissionais do Direito.</p>
    <br>
    <p>O c√≥digo completo deste projeto est√° dispon√≠vel no meu portf√≥lio. Contribui√ß√µes e discuss√µes s√£o bem-vindas.</p>
  </div>

</article>

<!-- ‚îÄ‚îÄ FOOTER ‚îÄ‚îÄ -->
<footer>
  <strong>Jonh Selmo</strong> &nbsp;¬∑&nbsp; Engenheiro de IA &nbsp;¬∑&nbsp; Processamento de Linguagem Natural &amp; IA Generativa
</footer>

<script>
  // ‚îÄ‚îÄ PROGRESS BAR ‚îÄ‚îÄ
  const bar = document.getElementById('progress');
  window.addEventListener('scroll', () => {
    const h = document.documentElement;
    const pct = (h.scrollTop / (h.scrollHeight - h.clientHeight)) * 100;
    bar.style.width = pct + '%';
  });

  // ‚îÄ‚îÄ FADE-IN ON SCROLL ‚îÄ‚îÄ
  const observer = new IntersectionObserver((entries) => {
    entries.forEach(e => { if (e.isIntersecting) { e.target.classList.add('visible'); } });
  }, { threshold: 0.08 });

  document.querySelectorAll('.fade-in').forEach(el => observer.observe(el));
</script>

</body>
</html>
